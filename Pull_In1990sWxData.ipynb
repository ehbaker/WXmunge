{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import pytz\n",
    "import CleanWxData as wx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "import LVL1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import settings\n",
    "Glacier='Wolverine'\n",
    "Station='990'\n",
    "\n",
    "data_columns, general_data_columns, out_date_format, precip_columns, precip_gage_change, primary_temp_column, temp_columns, timezone, wind_col, wind_dir_columns = settings.get_settings(settings.Glacier, settings.Station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wolverine990'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Glacier + Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (Glacier + Station== \"Gulkana1480\"):\n",
    "    par_dir=r\"Q:\\Project Data\\GlacierData\\Benchmark_Program\\Data/\" +Glacier+ r'/AllYears/Wx/Raw/telemeteredNWIS'\n",
    "if Glacier + Station ==\"Wolverine990\":\n",
    "    par_dir=r\"Q:\\Project Data\\GlacierData\\Benchmark_Program\\Data\\Wolverine\\AllYears\\Wx\\Raw\\telemeteredNWIS\\Historical_1995to2017\"\n",
    "    par_dir=r'C:\\Users\\ehbaker\\Documents\\Data\\Wolverine\\AllYears\\Wx\\Raw\\Telemetered'\n",
    "if Glacier + Station==\"Wolverine370\":\n",
    "    par_dir=r\"Q:\\Project Data\\GlacierData\\Benchmark_Program\\Data\\Wolverine\\AllYears\\Wx\\Raw\\telemeteredNWIS\\Historical_1997to2017StreamGage\"\n",
    "if Glacier + Station=='SouthCascade1640':\n",
    "    par_dir=r'Q:\\Project Data\\GlacierData\\Benchmark_Program\\Data\\SouthCascade\\AllYears\\Wx\\Raw\\telemeteredNWIS_gage_SCGMiddleTarn'\n",
    "if Glacier + Station=='SouthCascade1830':\n",
    "    par_dir=r'Q:\\Project Data\\GlacierData\\Benchmark_Program\\Data\\SouthCascade\\AllYears\\Wx\\Raw\\telemeteredNWIS_hut'\n",
    "\n",
    "os.chdir(par_dir)\n",
    "fls=glob.glob('*.csv')\n",
    "\n",
    "#Remove the summary file if already made previously\n",
    "if os.path.exists(\"NWIS_data_\"+Glacier + Station+\".csv\"):\n",
    "    fls.remove(\"NWIS_data_\"+Glacier + Station+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RelHum.csv\n",
      "RelHum\n",
      "Taspirated1.csv\n",
      "Taspirated1\n",
      "Taspirated2.csv\n",
      "Taspirated2\n",
      "Tpassive1.csv\n",
      "Tpassive1\n",
      "TPGCumulative.csv\n",
      "TPGCumulative\n",
      "VecAvgWindDir.csv\n",
      "VecAvgWindDir\n",
      "WindGustSpeed.csv\n",
      "WindGustSpeed\n",
      "WindSpeed.csv\n",
      "WindSpeed\n"
     ]
    }
   ],
   "source": [
    "#Make a single file with all the NWIS variables of interest\n",
    "alldat=pd.DataFrame()\n",
    "for fl in fls:\n",
    "    print(fl)\n",
    "    dat=pd.read_csv(fl, header=14)\n",
    "    var_name=fl.replace(\".csv\", \"\")\n",
    "    print(var_name)\n",
    "    dat=dat[['ISO 8601 UTC', 'Value']]\n",
    "    dat.rename(columns = {'Value': var_name}, inplace = True)\n",
    "    if fl==fls[0]:\n",
    "        alldat=alldat.append(dat)\n",
    "        continue\n",
    "    alldat=alldat.merge(dat, on='ISO 8601 UTC', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldat=alldat.rename(columns={'ISO 8601 UTC': \"UTC_time\"})\n",
    "\n",
    "#Convert wind gust speed from mph to m/s!! (this is only @ Wolv 990)\n",
    "if Glacier + Station == 'Wolverine990':\n",
    "    alldat.WindGustSpeed=alldat.WindGustSpeed * 0.44704 #convert from mph to m/s\n",
    "    alldat.WindSpeed=alldat.WindSpeed * 0.44704 #convert from mph to m/s\n",
    "\n",
    "#Convert english units to metric @ gage\n",
    "if Glacier +Station== 'Wolverine370':\n",
    "    alldat.TipIncremental= alldat.TipIncremental * 0.0254 #convert from inches to meters of precip\n",
    "    alldat.Discharge=alldat.Discharge * 0.0283168 #convert from ft3/s to m3/s\n",
    "    alldat.TPGCumulative=alldat.TPGCumulative/1000 #convert from mm to meters\n",
    "\n",
    "alldat['UTC_time']=pd.to_datetime(alldat.UTC_time, format='%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "#Set timezone of known UTC column\n",
    "alldat['UTC_time'].tz='UTC'\n",
    "\n",
    "#Create column for local time\n",
    "local_timezone=pytz.timezone(timezone) #create local timezone object (e.g. AK time)\n",
    "alldat=alldat.set_index('UTC_time')\n",
    "#Create column for local time\n",
    "local_timezone=pytz.timezone(timezone) #create local timezone object (e.g. AK time)\n",
    "\n",
    "#Re-sort on time index\n",
    "alldat=alldat.sort_index()\n",
    "\n",
    "for col in alldat.columns:\n",
    "    if 'Incremental' in col:\n",
    "        print('changing incremental to cumulative precipitation')\n",
    "        new_col_name=col.split('Incremental')[0] +'Cumulative'\n",
    "        incr_precip_col_name=col #save for later\n",
    "        alldat[new_col_name]=alldat[col].cumsum()\n",
    "\n",
    "#Drop the incremental precip col from the dataframe\n",
    "if 'incr_precip_col_name' in locals(): #if it exists\n",
    "    if Glacier+Station != 'Wolverine370':\n",
    "        print ('dropping incremental precip column')\n",
    "        alldat=alldat.drop(incr_precip_col_name, axis=1)\n",
    "\n",
    "if (Glacier + Station == 'SouthCascade1640') | (Glacier + Station == 'SouthCascade1830'):\n",
    "    fifteenmin_dat=pd.DataFrame()\n",
    "    for col in alldat:\n",
    "        print(col)\n",
    "        fifteenmin_dat[col]=wx.create_15min_from_hourly_data(alldat, col)\n",
    "    alldat=fifteenmin_dat.copy()\n",
    "\n",
    "#If there is hourly (not 15 min data)\n",
    "if Glacier + Station =='SouthCascade560':\n",
    "    start_15min_data='2014-05-15 15:15'\n",
    "    hourly_dat=alldat[:start_15min_data].copy()\n",
    "\n",
    "    full_range_15min = pd.date_range(hourly_dat.index[0], hourly_dat.index[-1], freq='15min')\n",
    "    hourly_dat=hourly_dat.reindex(index=full_range_15min, fill_value=pd.np.nan)\n",
    "\n",
    "    for col in hourly_dat.columns:\n",
    "        hourly_dat[col]=hourly_dat[col].interpolate(limit=3) #fill in 15 min vals from hourly, during time period not recorded\n",
    "\n",
    "    #Recombine with 15 minute logged data\n",
    "    new_dat=alldat[start_15min_data:].copy()\n",
    "    alldat=hourly_dat.append(new_dat)\n",
    "    alldat.drop(start_15min_data, inplace=True) #need this to drop the duplicate time @ the overlap point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inform index that the timezone is UTC\n",
    "alldat.index=alldat.index.tz_localize(tz='UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reindex to 15 min; include missing dates\n",
    "full_range_15minAll = pd.date_range(alldat.index[0], alldat.index[-1], freq='15min')\n",
    "alldat=alldat.reindex(index=full_range_15minAll, fill_value=pd.np.nan)\n",
    "\n",
    "#Wolverine River Stage Stuff\n",
    "if Glacier + Station== 'Wolverine370':\n",
    "    alldat[alldat.TipIncremental>1]=pd.np.nan\n",
    "\n",
    "    #Fill forwards according to data type\n",
    "    alldat.Tpassive1=alldat.Tpassive1.interpolate(limit=3) #comes as hourly; need to interpolate back to 15 min\n",
    "    Null_to_keep=alldat.index[alldat.TipIncremental.isnull() & alldat.TipIncremental.shift(1).isnull() &alldat.TipIncremental.shift(-1).isnull()]\n",
    "    alldat.TipIncremental=alldat.TipIncremental.fillna(value=0)\n",
    "    alldat.loc[alldat.index.isin(Null_to_keep), 'TipIncremental']=pd.np.nan\n",
    "\n",
    "    #Set uncertain precip data to NAN (pre 2005)\n",
    "    alldat.loc[:'2004', 'TipIncremental']=pd.np.nan #Can't tell what is happening with these; huge #s, but don't seem to be simply cumulative? Change in units? Something else? Very hard to say.\n",
    "\n",
    "    alldat['TipCumulative']=alldat.TipIncremental.cumsum()\n",
    "\n",
    "    \n",
    "#SouthCascade Specific Stuff\n",
    "if Glacier + Station=='SouthCascade1830':\n",
    "    alldat[new_col_name]=alldat[new_col_name]*1000 #convert from mm to meters\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tpassive1',\n",
       " 'Tpassive2',\n",
       " 'TAspirated1',\n",
       " 'TAspirated2',\n",
       " 'TPGCumulative',\n",
       " 'StageCumulative',\n",
       " 'WindSpeed',\n",
       " 'WindDir',\n",
       " 'VecAvgWindDir',\n",
       " 'RelHum',\n",
       " 'WindSpeed',\n",
       " 'WindGustSpeed',\n",
       " 'Barom']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(settings)\n",
    "temp_columns +precip_columns +[wind_col] +wind_dir_columns+general_data_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if only dealing with partial time subset of dataset\n",
    "not_used_cols=set(data_columns) -set(alldat.columns.unique())\n",
    "\n",
    "for col in not_used_cols:\n",
    "    alldat[col]=pd.np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time format stuff\n",
    "date_format='%Y/%m/%d %H:%M'\n",
    "\n",
    "#Set output format of time\n",
    "alldat['UTC_time']=alldat.index.strftime(date_format)#Create column for true local time (as string, not UTC - X hrs)\n",
    "alldat['local_time']=alldat.index.tz_convert(timezone).strftime(date_format)#Create column for true local time (as string, not UTC - X hrs)\n",
    "\n",
    "out_col_order= ['UTC_time', 'local_time'] +data_columns\n",
    "save_dat=alldat[out_col_order].copy()\n",
    "\n",
    "#Ensure data does not have duplicates\n",
    "save_dat.drop_duplicates(inplace=True)\n",
    "\n",
    "save_dat.to_csv(\"NWIS_data_\" + Glacier+ Station +\".csv\", index=False, float_format='%g')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_dat.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-10-11 09:00:00+0000', tz='UTC', freq='15T')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dat.first_valid_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other plots and such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using figsize to make the figure a little bigger, 10\"x5\"\n",
    "# fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(nrows=2, ncols=3, sharex=False, sharey=False, figsize=(10,5))\n",
    "\n",
    "# for ax in fig.axes:\n",
    "#     plt.sca(ax)\n",
    "#     plt.xticks(rotation=90)\n",
    "\n",
    "# # Doing each of these manually (ugh)\n",
    "# yr='2001'\n",
    "# alldat.TipIncremental[yr].plot(ax=ax1)\n",
    "# total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "# ax1.set_title(str(yr)+\": total precip = \"+ str(total_precip))\n",
    "\n",
    "# yr='2002'\n",
    "# alldat.TipIncremental[yr].plot(ax=ax2)\n",
    "# total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "# ax2.set_title(str(yr)+\": total precip = \"+ str(total_precip))\n",
    "\n",
    "# yr='2003'\n",
    "# alldat.TipIncremental[yr].plot(ax=ax3)\n",
    "# total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "# ax3.set_title(str(yr)+\": total precip = \"+ str(total_precip))\n",
    "\n",
    "# yr='2004'\n",
    "# alldat.TipIncremental[yr].plot(ax=ax4)\n",
    "# total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "# ax4.set_title(str(yr)+\": total precip = \"+ str(total_precip))\n",
    "\n",
    "# yr='2005'\n",
    "# alldat.TipIncremental[yr].plot(ax=ax5)\n",
    "# total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "# ax5.set_title(str(yr)+\": total precip = \"+ str(total_precip))\n",
    "\n",
    "# yr='2007'\n",
    "# alldat.TipIncremental[yr].plot(ax=ax6)\n",
    "# total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "# ax6.set_title(str(yr)+\": total precip = \"+ str(total_precip))\n",
    "\n",
    "# # df[df['Country'] == 'Iran'].plot(x='Year', y='GDP_per_capita', legend=False, ax=ax2)\n",
    "# # ax2.set_title(\"Iran\")\n",
    "# # df[df['Country'] == 'France'].plot(x='Year', y='GDP_per_capita', legend=False, ax=ax3)\n",
    "# # ax3.set_title(\"France\")\n",
    "# # df[df['Country'] == 'Ireland'].plot(x='Year', y='GDP_per_capita', legend=False, ax=ax4)\n",
    "# # ax4.set_title(\"Ireland\")\n",
    "# # df[df['Country'] == 'Kazakhstan'].plot(x='Year', y='GDP_per_capita', legend=False, ax=ax5)\n",
    "# # ax5.set_title(\"Kazakhstan\")\n",
    "# # df[df['Country'] == 'United Arab Emirates'].plot(x='Year', y='GDP_per_capita', legend=False, ax=ax6)\n",
    "# # ax6.set_title(\"United Arab Emirates\")\n",
    "\n",
    "# # If you don't do tight_layout() you'll have weird overlaps\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.tight_layout()\n",
    "\n",
    "# #plt.savefig(r'Q:\\Project Data\\GlacierData\\Benchmark_Program\\Data\\Wolverine\\AllYears\\Wx\\Raw\\telemeteredNWIS\\Historical_1997to2017StreamGage\\rawdataplots2001to2007.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alldat.TipIncremental['2005-06-28 18':'2005-06-28 21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldat['time']=alldat.index\n",
    "alldat['tdiff']=(alldat['time'].diff())\n",
    "\n",
    "(alldat.tdiff > pd.to_timedelta('15M')).any()\n",
    "alldat[(alldat.tdiff > pd.to_timedelta('15M'))]\n",
    "\n",
    "#COME BACK AND FIX THIS AT SOME POINT.... yikesers\n",
    "\n",
    "#Determine which years have cumulative precip, and which have incremental.\n",
    "if Glacier + Station=='Wolverine370':\n",
    "    alldat['month']=alldat.index.month\n",
    "    alldat.loc[~alldat.month.isin([6,7,8,9]), 'TipIncremental']=pd.np.nan #first, set non-summer months to NAN\n",
    "# alldat.loc['2001-01':'2001-08-08', 'TipIncremental']=pd.np.nan #this data looks bad; unknown\n",
    "\n",
    "# incr_years=['2001', '2002', '2003' '2004']\n",
    "# cum_years=[]\n",
    "# bad_yrs=['2009', '2010', '2011']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alldat.loc[alldat.TipIncremental>50, 'TipIncremental']=pd.np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alldat['month']=alldat.index.month\n",
    "# alldat.month.isin([6,7,8,9])\n",
    "# alldat.loc[~alldat.month.isin([6,7,8,9]), 'TipIncremental']=pd.np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_increment=alldat.TipIncremental[alldat.TipIncremental.notnull()]['2002':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# ax=alldat.TipIncremental['2005-06-28 18':'2005-06-28 21'].cumsum().plot()\n",
    "# #alldat.TipIncremental.cumsum(skipna=True).plot(marker='o', ms=3, color='red', ax=ax)\n",
    "# #plt.legend(['From Cumulative File', 'From Incremental File'])\n",
    "# plt.title(\"Full Record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# yr='2012'\n",
    "# alldat.TipIncremental[yr].cumsum().plot()\n",
    "# total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "# plt.title(str(yr)+\": total precip = \"+ str(total_precip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using figsize to make the figure a little bigger, 10\"x5\"\n",
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(nrows=2, ncols=3, sharex=False, sharey=False, figsize=(10,5))\n",
    "\n",
    "for ax in fig.axes:\n",
    "    plt.sca(ax)\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "# Doing each of these manually (ugh)\n",
    "yr='2001'\n",
    "alldat.TipIncremental[yr].cumsum().plot(ax=ax1)\n",
    "total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "ax1.set_title(str(yr)+\": total precip = \"+ str(total_precip))\n",
    "\n",
    "yr='2002'\n",
    "alldat.TipIncremental[yr].cumsum().plot(ax=ax2)\n",
    "total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "ax2.set_title(str(yr)+\": total precip = \"+ str(total_precip))\n",
    "\n",
    "yr='2003'\n",
    "alldat.TipIncremental[yr].cumsum().plot(ax=ax3)\n",
    "total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "ax3.set_title(str(yr)+\": total precip = \"+ str(total_precip))\n",
    "\n",
    "yr='2004'\n",
    "alldat.TipIncremental[yr].cumsum().plot(ax=ax4)\n",
    "total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "ax4.set_title(str(yr)+\": total precip = \"+ str(total_precip))\n",
    "\n",
    "yr='2005'\n",
    "alldat.TipIncremental[yr].cumsum().plot(ax=ax5)\n",
    "total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "ax5.set_title(str(yr)+\": total precip = \"+ str(total_precip))\n",
    "\n",
    "yr='2007'\n",
    "alldat.TipIncremental[yr].cumsum().plot(ax=ax6)\n",
    "total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "ax6.set_title(str(yr)+\": total precip = \"+ str(total_precip))\n",
    "\n",
    "# df[df['Country'] == 'Iran'].plot(x='Year', y='GDP_per_capita', legend=False, ax=ax2)\n",
    "# ax2.set_title(\"Iran\")\n",
    "# df[df['Country'] == 'France'].plot(x='Year', y='GDP_per_capita', legend=False, ax=ax3)\n",
    "# ax3.set_title(\"France\")\n",
    "# df[df['Country'] == 'Ireland'].plot(x='Year', y='GDP_per_capita', legend=False, ax=ax4)\n",
    "# ax4.set_title(\"Ireland\")\n",
    "# df[df['Country'] == 'Kazakhstan'].plot(x='Year', y='GDP_per_capita', legend=False, ax=ax5)\n",
    "# ax5.set_title(\"Kazakhstan\")\n",
    "# df[df['Country'] == 'United Arab Emirates'].plot(x='Year', y='GDP_per_capita', legend=False, ax=ax6)\n",
    "# ax6.set_title(\"United Arab Emirates\")\n",
    "\n",
    "# If you don't do tight_layout() you'll have weird overlaps\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(r'Q:\\Project Data\\GlacierData\\Benchmark_Program\\Data\\Wolverine\\AllYears\\Wx\\Raw\\telemeteredNWIS\\Historical_1997to2017StreamGage\\rawdataplots2001to2007.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using figsize to make the figure a little bigger, 10\"x5\"\n",
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(nrows=2, ncols=3, sharex=False, sharey=False, figsize=(10,5))\n",
    "\n",
    "for ax in fig.axes:\n",
    "    plt.sca(ax)\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "# Doing each of these manually (ugh)\n",
    "yr='2008'\n",
    "alldat.TipIncremental[yr].cumsum().plot(ax=ax1)\n",
    "total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "ax1.set_title(str(yr)+\": total precip = \"+ str(total_precip))\n",
    "\n",
    "yr='2009'\n",
    "alldat.TipIncremental[yr].cumsum().plot(ax=ax2)\n",
    "total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "ax2.set_title(str(yr)+\": total precip = \"+ str(total_precip))\n",
    "\n",
    "yr='2010'\n",
    "alldat.TipIncremental[yr].cumsum().plot(ax=ax3)\n",
    "total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "ax3.set_title(str(yr)+\": total precip = \"+ str(total_precip))\n",
    "\n",
    "yr='2011'\n",
    "alldat.TipIncremental[yr].cumsum().plot(ax=ax4)\n",
    "total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "ax4.set_title(str(yr)+\": total precip = \"+ str(total_precip))\n",
    "\n",
    "yr='2012'\n",
    "alldat.TipIncremental[yr].cumsum().plot(ax=ax5)\n",
    "total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "ax5.set_title(str(yr)+\": total precip = \"+ str(total_precip))\n",
    "\n",
    "yr='2013'\n",
    "alldat.TipIncremental[yr].cumsum().plot(ax=ax6)\n",
    "total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "ax6.set_title(str(yr)+\": total precip = \"+ str(total_precip))\n",
    "\n",
    "# df[df['Country'] == 'Iran'].plot(x='Year', y='GDP_per_capita', legend=False, ax=ax2)\n",
    "# ax2.set_title(\"Iran\")\n",
    "# df[df['Country'] == 'France'].plot(x='Year', y='GDP_per_capita', legend=False, ax=ax3)\n",
    "# ax3.set_title(\"France\")\n",
    "# df[df['Country'] == 'Ireland'].plot(x='Year', y='GDP_per_capita', legend=False, ax=ax4)\n",
    "# ax4.set_title(\"Ireland\")\n",
    "# df[df['Country'] == 'Kazakhstan'].plot(x='Year', y='GDP_per_capita', legend=False, ax=ax5)\n",
    "# ax5.set_title(\"Kazakhstan\")\n",
    "# df[df['Country'] == 'United Arab Emirates'].plot(x='Year', y='GDP_per_capita', legend=False, ax=ax6)\n",
    "# ax6.set_title(\"United Arab Emirates\")\n",
    "\n",
    "# If you don't do tight_layout() you'll have weird overlaps\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(r'Q:\\Project Data\\GlacierData\\Benchmark_Program\\Data\\Wolverine\\AllYears\\Wx\\Raw\\telemeteredNWIS\\Historical_1997to2017StreamGage\\rawdataplots2008to2013.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using figsize to make the figure a little bigger, 10\"x5\"\n",
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(nrows=2, ncols=3, sharex=False, sharey=False, figsize=(10,5))\n",
    "\n",
    "for ax in fig.axes:\n",
    "    plt.sca(ax)\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "# Doing each of these manually (ugh)\n",
    "yr='2013'\n",
    "alldat.TipIncremental[yr].cumsum().plot(ax=ax1)\n",
    "total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "ax1.set_title(str(yr)+\": total precip = \"+ str(total_precip))\n",
    "\n",
    "yr='2014'\n",
    "alldat.TipIncremental[yr].cumsum().plot(ax=ax2)\n",
    "total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "ax2.set_title(str(yr)+\": total precip = \"+ str(total_precip))\n",
    "\n",
    "yr='2015'\n",
    "alldat.TipIncremental[yr].cumsum().plot(ax=ax3)\n",
    "total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "ax3.set_title(str(yr)+\": total precip = \"+ str(total_precip))\n",
    "\n",
    "yr='2016'\n",
    "alldat.TipIncremental[yr].cumsum().plot(ax=ax4)\n",
    "total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "ax4.set_title(str(yr)+\": total precip = \"+ str(total_precip))\n",
    "\n",
    "yr='2017'\n",
    "alldat.TipIncremental[yr].cumsum().plot(ax=ax5)\n",
    "total_precip=alldat.TipIncremental[yr].cumsum()[alldat.TipIncremental[yr].cumsum().last_valid_index()]\n",
    "ax5.set_title(str(yr)+\": total precip = \"+ str(total_precip))\n",
    "\n",
    "# df[df['Country'] == 'Iran'].plot(x='Year', y='GDP_per_capita', legend=False, ax=ax2)\n",
    "# ax2.set_title(\"Iran\")\n",
    "# df[df['Country'] == 'France'].plot(x='Year', y='GDP_per_capita', legend=False, ax=ax3)\n",
    "# ax3.set_title(\"France\")\n",
    "# df[df['Country'] == 'Ireland'].plot(x='Year', y='GDP_per_capita', legend=False, ax=ax4)\n",
    "# ax4.set_title(\"Ireland\")\n",
    "# df[df['Country'] == 'Kazakhstan'].plot(x='Year', y='GDP_per_capita', legend=False, ax=ax5)\n",
    "# ax5.set_title(\"Kazakhstan\")\n",
    "# df[df['Country'] == 'United Arab Emirates'].plot(x='Year', y='GDP_per_capita', legend=False, ax=ax6)\n",
    "# ax6.set_title(\"United Arab Emirates\")\n",
    "\n",
    "# If you don't do tight_layout() you'll have weird overlaps\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(r'Q:\\Project Data\\GlacierData\\Benchmark_Program\\Data\\Wolverine\\AllYears\\Wx\\Raw\\telemeteredNWIS\\Historical_1997to2017StreamGage\\rawdataplots2013to2017.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldat[['TipCumulative', 'TipIncremental', 'Tpassive1']].plot()\n",
    "plt.ylim(-1, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldat.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat1=pd.read_csv(\"Q:\\Project Data\\GlacierData\\Benchmark_Program\\Data\\Wolverine\\AllYears\\Wx\\Raw\\StreamGage\\wlca2_2015.csv\", infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip=dat1.P_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip=precip.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "precip.dropna().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "alldat.TipIncremental.cumsum()['2015'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
