{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# LVL2 Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import external libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "#pd.options.mode.chained_assignment = None  # default='warn'; chained index warning\n",
    "import numpy as np\n",
    "import imp\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "#plotting\n",
    "%matplotlib notebook\n",
    "\n",
    "#import self-written libraries\n",
    "import LVL1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Data Import Tasks\n",
    "#path to level 1 data\n",
    "Glacier=\"Gulkana\" #or \"Gulkana\"\n",
    "Station=\"1725\" #or other elevations; this depends on the naming convention of input data\n",
    "timezone='America/Anchorage' #choose from pytz.all_timezones\n",
    "\n",
    "file_label='_15min'\n",
    "yr='all' #either \"all\" or the year you want\n",
    "\n",
    "pth=r\"Q:/Project Data/GlacierData/Benchmark_Program/Data/\" +Glacier+ r\"/AllYears/Wx/LVL1/emily/\" + Glacier.lower()+Station+file_label+yr+\".csv\"\n",
    "\n",
    "#time format and column\n",
    "Local_time_column_name='Local_time'\n",
    "date_format='%Y/%m/%d %H:%M'\n",
    "\n",
    "#directory to save output data\n",
    "save_dir=r\"Q:/Project Data/GlacierData/Benchmark_Program/Data/\" +Glacier+ r\"/AllYears/Wx/LVL2/emily/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:/Project Data/GlacierData/Benchmark_Program/Data/Gulkana/AllYears/Wx/LVL1/emily/gulkana1725_15minall.csv\n"
     ]
    }
   ],
   "source": [
    "#read in level1 CSV\n",
    "dat=pd.read_csv(pth)\n",
    "print(pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat['local_time']=pd.to_datetime(dat[Local_time_column_name], format= date_format)\n",
    "dat=dat.set_index('local_time') #set this local time as the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Give names of columns containing temperature, and precipitation data, data for general averaging, and wind direction\n",
    "temp_columns=['Tpassive1', 'Tpassive2', 'TAspirated1', 'TAspirated2']\n",
    "primary_temp_column='TAspirated1'\n",
    "if (Glacier +Station=='Gulkana1920')| (Glacier + Station=='Wolverine1420'):\n",
    "    primary_temp_column='Tpassive1'\n",
    "#unaspirated_temp_columns=['Tpassive1', 'Tpassive2']\n",
    "\n",
    "precip_columns=['StageCumulative', 'TPGCumulative']\n",
    "general_data_columns=['RelHum', 'WindSpeed', 'WindGustSpeed', 'RadiationIn', 'RadiationOut', 'SnowDepth']\n",
    "wind_dir_columns=['WindDir', 'VecAvgWindDir']\n",
    "wind_speed_column=['WindSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incremental_precip_columns=[] #create names for incremental precip columns\n",
    "for precip_col in precip_columns:\n",
    "    col_name=precip_col.split(\"Cumulative\")[0]+\"Incremental\"\n",
    "    incremental_precip_columns.append(col_name)\n",
    "    dat[col_name]=dat[precip_col]-dat[precip_col].shift(1)\n",
    "    if not np.isnan(dat[precip_col][0]):\n",
    "        dat.ix[0, col_name]=0 #set first value to 0, not NAN IF the initial cumulative series was also not null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill Gaps -temp\n",
    " #### * 15 min data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Temperature - for primary sensor, fill gaps. \n",
    "#  for <3 len gap, fill with linear interpolation\n",
    "dat.loc[:,primary_temp_column]=dat[primary_temp_column].interpolate(method='linear', limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  for gaps >3, fill with average of passive temperature sensors, as long as the passive sensors agree\n",
    "\n",
    "#Store locations of long NAN gaps to be filled\n",
    "primary_temp_null_indx=dat[primary_temp_column].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#List alternate temp columns\n",
    "secondary_temp_columns=list(set(temp_columns)-set([primary_temp_column]))\n",
    "passive_temp_columns=[s for s in temp_columns if \"passive\" in s]\n",
    "\n",
    "#Subset data to alternate temperature columns\n",
    "secondary_temp_dat=dat[secondary_temp_columns].copy()\n",
    "#Calculate the mean of the secondary temp values\n",
    "secondary_temp_dat['temp_mean']=secondary_temp_dat[secondary_temp_columns].mean(axis=1)\n",
    "#Calculate standard dev. of secondary temp values\n",
    "secondary_temp_dat['temp_sd']=secondary_temp_dat[secondary_temp_columns].std(axis=1)\n",
    "#Calculate temperature difference between avg. of other temperatures\n",
    "secondary_temp_dat['temp_diff']=abs(dat[primary_temp_column]-secondary_temp_dat.mean(axis=1))\n",
    "#Calculate the median of secondary temp values\n",
    "secondary_temp_dat['temp_median']=secondary_temp_dat[secondary_temp_columns].median(axis=1)\n",
    "#Calculate mean of passive temperature sensors (if a sensor is missing, mean will be NAN)\n",
    "secondary_temp_dat['passive_average']=dat[passive_temp_columns].mean(axis=1, skipna=False)\n",
    "#Calculate difference of 2 passive sensors from one another\n",
    "secondary_temp_dat['passive_difference_between_sensors']=abs(dat[passive_temp_columns[0]]-dat[passive_temp_columns[1]])\n",
    "\n",
    "#Fill remaining gaps (>3 length) in primary timeseries with average of all other sensors\n",
    "dat.loc[dat[primary_temp_column].isnull(), primary_temp_column]=secondary_temp_dat.temp_mean[dat[primary_temp_column].isnull()]\n",
    "\n",
    "#Second round of interpolating small gaps\n",
    "dat[primary_temp_column]=dat[primary_temp_column].interpolate(method='linear', limit=3) #interpolate small gaps again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Find places where passive differs from aspirated\n",
    "asp_more_than_2deg_diff_from_passivemean_idx=(abs(dat[primary_temp_column]- secondary_temp_dat.passive_average))>2 #difference between asp and passive mean > 2 deg\n",
    "\n",
    "#In places where the passive AGREE with eachother, but DISAGREE with the aspirated mean, set main aspirated T to mean of passive.\n",
    "passive_sensors_agree_with_eachother_2deg_idx=secondary_temp_dat.passive_difference_between_sensors<2 #passive sensors agree with eachother (<2 deg diff)\n",
    "dat.loc[asp_more_than_2deg_diff_from_passivemean_idx & passive_sensors_agree_with_eachother_2deg_idx, primary_temp_column]=secondary_temp_dat.loc[asp_more_than_2deg_diff_from_passivemean_idx & passive_sensors_agree_with_eachother_2deg_idx,'passive_average'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Final outlier strip\n",
    "dat[primary_temp_column]=LVL1.hampel(dat[primary_temp_column], k=7) #this may not be neccessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save final 15 minute data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_columns=[primary_temp_column] +incremental_precip_columns+general_data_columns #columns to include in output\n",
    "save_name=Glacier.lower()+ Station + \"_15min_\"+\"LVL2.csv\" #filename\n",
    "save_pth=os.path.join(save_dir, save_name)\n",
    "\n",
    "save_dat=dat[out_columns] #dataframe with final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat[out_columns].to_csv(save_pth, float_format='%g', date_format=date_format) #save data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hourly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create Hourly Data -\n",
    "#Temperature\n",
    "hourly_dat=pd.DataFrame()\n",
    "for temp_col in temp_columns:\n",
    "    #Create WMO Mean Temp\n",
    "    hourly_dat[temp_col+\"_min\"]=dat[temp_col].resample('H').min()\n",
    "    hourly_dat[temp_col+ \"_max\"]=dat[temp_col].resample('H').max()\n",
    "    hourly_dat[temp_col+\"_WMO\"]=hourly_dat[[temp_col+\"_min\", temp_col+'_max']].mean(axis=1)\n",
    "    #Create USGS Mean Temp\n",
    "    hourly_dat[temp_col+\"_USGS\"]=dat[temp_col].resample('H').mean()\n",
    "    \n",
    "#Precipitation\n",
    "for incremental_precip_col in incremental_precip_columns:\n",
    "    hourly_dat[incremental_precip_col]=dat[incremental_precip_col].resample('H', label='left').sum() #all precip recieved during his hour\n",
    "    \n",
    "#Other Data Types (that can be aggregated with a simple mean)\n",
    "for general_data_col in general_data_columns:\n",
    "    hourly_dat[general_data_col]=dat[general_data_col].resample('H').mean()\n",
    "\n",
    "#Wind Direction - this process is for data that is logged as vector-averaged \n",
    "  # for data that is not, use LVL1.vector_average_wind_direction\n",
    "for wd_col in wind_dir_columns:\n",
    "#Convert to raidans\n",
    "    dat['wind_dir_cos']=np.cos(dat[wd_col]*(np.pi/180))\n",
    "    dat['wind_dir_sin']=np.sin(dat[wd_col]*(np.pi/180))\n",
    "\n",
    "    #Calculate mean of x and y directions in radian space\n",
    "    hourly_dat['wind_dir_cos']=dat.wind_dir_cos.resample('H').mean()\n",
    "    hourly_dat['wind_dir_sin']=dat.wind_dir_sin.resample('H').mean()\n",
    "\n",
    "    #Convert back to 0-360 coordinates\n",
    "    hourly_dat[wd_col]=(np.arctan2(hourly_dat.wind_dir_sin, hourly_dat.wind_dir_cos) * 180/np.pi)\n",
    "    hourly_dat.loc[hourly_dat[wd_col]<0, wd_col]+=360 #add 360 where hourly dat less than 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:/Project Data/GlacierData/Benchmark_Program/Data/Gulkana/AllYears/Wx/LVL2/emily/gulkana1725_hourly_LVL2.csv\n"
     ]
    }
   ],
   "source": [
    "out_temp_columns = [s for s in hourly_dat.columns if primary_temp_column in s]\n",
    "\n",
    "out_columns=out_temp_columns+incremental_precip_columns+general_data_columns+ wind_dir_columns #columns to include in output\n",
    "save_name=Glacier.lower()+ Station + \"_hourly_\"+\"LVL2.csv\" #filename\n",
    "save_pth=os.path.join(save_dir, save_name)\n",
    "\n",
    "hourly_dat[out_columns][:-1].to_csv(save_pth, float_format='%g') #write selected columns; omit last row (unlikely to be complete, with download)\n",
    "print(save_pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_dat=pd.DataFrame() #create empty dataframe\n",
    "\n",
    "#Temperature\n",
    "for temp_col in temp_columns:\n",
    "    #Create WMO Mean Temp\n",
    "    daily_dat[temp_col+\"_min\"]=dat[temp_col].resample('D').min()\n",
    "    daily_dat[temp_col+ \"_max\"]=dat[temp_col].resample('D').max()\n",
    "    daily_dat[temp_col+\"_WMO\"]=daily_dat[[temp_col+\"_min\", temp_col+'_max']].mean(axis=1)\n",
    "    #Create USGS Mean Temp\n",
    "    daily_dat[temp_col+\"_USGS\"]=dat[temp_col].resample('D').mean()    \n",
    "    \n",
    "#Precipitation\n",
    "for incremental_precip_col in incremental_precip_columns:\n",
    "    daily_dat[incremental_precip_col]=dat[incremental_precip_col].resample('D', label='left').sum() #all precip recieved during this day; label on right\n",
    "    \n",
    "#Other Data Types (that can be aggregated with a simple mean)\n",
    "for general_data_col in general_data_columns:\n",
    "    daily_dat[general_data_col]=dat[general_data_col].resample('D').mean()\n",
    "\n",
    "#Wind Direction - this process is for data that is logged as vector-averaged \n",
    "  # for data that is not, use LVL2.vector_average_wind_direction to create\n",
    "for wd_col in wind_dir_columns:    \n",
    "    #Convert to raidans\n",
    "    dat['wind_dir_cos']=np.cos(dat[wd_col]*(np.pi/180))\n",
    "    dat['wind_dir_sin']=np.sin(dat[wd_col]*(np.pi/180))\n",
    "\n",
    "    #Calculate mean of x and y directions in radian space\n",
    "    daily_dat['wind_dir_cos']=dat.wind_dir_cos.resample('D').mean()\n",
    "    daily_dat['wind_dir_sin']=dat.wind_dir_sin.resample('D').mean()\n",
    "\n",
    "    #Convert back to 0-360 coordinates\n",
    "    daily_dat[wd_col]=(np.arctan2(daily_dat.wind_dir_sin, daily_dat.wind_dir_cos) * 180/np.pi)\n",
    "    daily_dat.loc[daily_dat[wd_col]<0, wd_col]+=360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_temp_columns = [s for s in daily_dat.columns if primary_temp_column in s] #only save select temperature columns\n",
    "\n",
    "out_columns=out_temp_columns+incremental_precip_columns+general_data_columns+ wind_dir_columns #columns to include in output\n",
    "save_name=Glacier.lower()+ Station + \"_daily_\"+\"LVL2.csv\" #filename\n",
    "save_pth=os.path.join(save_dir, save_name) #location to save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Set number of decimals to save for each type of data. Split into 3 separate loops for easy option of changing for each type.\n",
    "for col in out_temp_columns:\n",
    "    daily_dat[col]=[\"%.1f\" %x for x in daily_dat[col]] #round temperature to 1 decimal places; store as string \n",
    "\n",
    "for col in incremental_precip_columns:\n",
    "    daily_dat[col]=[\"%.1f\" %x for x in daily_dat[col]] #round precip to 1 decimal place\n",
    "\n",
    "for col in general_data_columns:\n",
    "    daily_dat[col]=[\"%.1f\" %x for x in daily_dat[col]] #round general data cols to 1 decimal place\n",
    "\n",
    "for col in wind_dir_columns:\n",
    "    daily_dat[col]=[\"%.0f\" %x for x in daily_dat[col]] #wind direction; no decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rename columns to standard\n",
    "# #Generic Temperature Label\n",
    "# final_names=[x.replace(primary_temp_column, 'Temp') for x in out_columns]\n",
    "# #Change precip label from Incremental to Precip (preserve type label)\n",
    "# final_names=[x.replace(\"Incremental\", \"_Precip\") for x in final_names]\n",
    "# save_dat.columns=final_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_dat=daily_dat[out_columns][:-1] #remove last row; day is not complete upon download\n",
    "save_dat.to_csv(save_pth, float_format='%g', date_format='%Y/%m/%d') #write selected columns; omit last row (unlikely to be complete, with download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q:/Project Data/GlacierData/Benchmark_Program/Data/Gulkana/AllYears/Wx/LVL2/emily/gulkana1725_daily_LVL2.csv'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TAspirated1_min</th>\n",
       "      <th>TAspirated1_max</th>\n",
       "      <th>TAspirated1_WMO</th>\n",
       "      <th>TAspirated1_USGS</th>\n",
       "      <th>StageIncremental</th>\n",
       "      <th>TPGIncremental</th>\n",
       "      <th>RelHum</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>RadiationIn</th>\n",
       "      <th>RadiationOut</th>\n",
       "      <th>SnowDepth</th>\n",
       "      <th>WindDir</th>\n",
       "      <th>VecAvgWindDir</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-17</th>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.1</td>\n",
       "      <td>nan</td>\n",
       "      <td>86.3</td>\n",
       "      <td>20.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>nan</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-18</th>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>nan</td>\n",
       "      <td>10.2</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.7</td>\n",
       "      <td>nan</td>\n",
       "      <td>111.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>nan</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-19</th>\n",
       "      <td>-1.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>nan</td>\n",
       "      <td>3.5</td>\n",
       "      <td>nan</td>\n",
       "      <td>2.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>146.4</td>\n",
       "      <td>50.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>nan</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-20</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>nan</td>\n",
       "      <td>9.1</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.6</td>\n",
       "      <td>nan</td>\n",
       "      <td>95.7</td>\n",
       "      <td>24.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-21</th>\n",
       "      <td>3.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>nan</td>\n",
       "      <td>2.7</td>\n",
       "      <td>nan</td>\n",
       "      <td>3.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>141.3</td>\n",
       "      <td>24.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>nan</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TAspirated1_min TAspirated1_max TAspirated1_WMO TAspirated1_USGS  \\\n",
       "local_time                                                                    \n",
       "2017-08-17            -1.5             0.2            -0.7             -0.7   \n",
       "2017-08-18            -1.5             0.8            -0.3             -0.5   \n",
       "2017-08-19            -1.8             3.0             0.6              0.3   \n",
       "2017-08-20            -0.1             4.6             2.2              1.7   \n",
       "2017-08-21             3.7             6.0             4.8              4.8   \n",
       "\n",
       "           StageIncremental TPGIncremental RelHum WindSpeed WindGustSpeed  \\\n",
       "local_time                                                                  \n",
       "2017-08-17              nan            4.0    nan       1.1           nan   \n",
       "2017-08-18              nan           10.2    nan       1.7           nan   \n",
       "2017-08-19              nan            3.5    nan       2.0           nan   \n",
       "2017-08-20              nan            9.1    nan       4.6           nan   \n",
       "2017-08-21              nan            2.7    nan       3.9           nan   \n",
       "\n",
       "           RadiationIn RadiationOut SnowDepth WindDir VecAvgWindDir  \n",
       "local_time                                                           \n",
       "2017-08-17        86.3         20.3       2.3     nan           203  \n",
       "2017-08-18       111.0         18.5       2.3     nan           197  \n",
       "2017-08-19       146.4         50.8       2.3     nan           224  \n",
       "2017-08-20        95.7         24.2       1.9     nan           221  \n",
       "2017-08-21       141.3         24.2       2.3     nan            14  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dat.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\ehbaker\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2133\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2134\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2135\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\src\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\src\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2306bf771229>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_dat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\ehbaker\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2057\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ehbaker\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2067\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ehbaker\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ehbaker\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3542\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3543\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3544\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3545\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ehbaker\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2134\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2136\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\src\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\src\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
