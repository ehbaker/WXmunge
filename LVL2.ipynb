{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# LVL2 Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import external libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "#pd.options.mode.chained_assignment = None  # default='warn'; chained index warning\n",
    "import numpy as np\n",
    "import imp\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "#plotting\n",
    "%matplotlib notebook\n",
    "\n",
    "#import self-written libraries\n",
    "import LVL1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Data Import Tasks\n",
    "#path to level 1 data\n",
    "Glacier=\"Gulkana\" #or \"Gulkana\"\n",
    "Station=\"1725\" #or other elevations; this depends on the naming convention of input data\n",
    "timezone='America/Anchorage' #choose from pytz.all_timezones\n",
    "\n",
    "file_label='_15min'\n",
    "yr='all' #either \"all\" or the year you want\n",
    "\n",
    "pth=r\"Q:/Project Data/GlacierData/Benchmark_Program/Data/\" +Glacier+ r\"/AllYears/Wx/LVL1/emily/\" + Glacier.lower()+Station+file_label+yr+\".csv\"\n",
    "\n",
    "#time format and column\n",
    "Local_time_column_name='Local_time'\n",
    "date_format='%Y/%m/%d %H:%M'\n",
    "\n",
    "#directory to save output data\n",
    "save_dir=r\"Q:/Project Data/GlacierData/Benchmark_Program/Data/\" +Glacier+ r\"/AllYears/Wx/LVL2/emily/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:/Project Data/GlacierData/Benchmark_Program/Data/Gulkana/AllYears/Wx/LVL1/emily/gulkana1725_15minall.csv\n"
     ]
    }
   ],
   "source": [
    "#read in level1 CSV\n",
    "dat=pd.read_csv(pth)\n",
    "print(pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat['local_time']=pd.to_datetime(dat[Local_time_column_name], format= date_format)\n",
    "dat=dat.set_index('local_time') #set this local time as the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Give names of columns containing temperature, and precipitation data, data for general averaging, and wind direction\n",
    "temp_columns=['Tpassive1', 'Tpassive2', 'TAspirated1', 'TAspirated2']\n",
    "primary_temp_column='TAspirated1'\n",
    "if (Glacier +Station=='Gulkana1920')| (Glacier + Station=='Wolverine1420'):\n",
    "    primary_temp_column='Tpassive1'\n",
    "#unaspirated_temp_columns=['Tpassive1', 'Tpassive2']\n",
    "\n",
    "precip_columns=['StageCumulative', 'TPGCumulative']\n",
    "general_data_columns=['RelHum', 'WindSpeed', 'WindGustSpeed', 'RadiationIn', 'RadiationOut', 'SnowDepth']\n",
    "wind_dir_columns=['WindDir', 'VecAvgWindDir']\n",
    "wind_speed_column=['WindSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incremental_precip_columns=[] #create names for incremental precip columns\n",
    "for precip_col in precip_columns:\n",
    "    col_name=precip_col.split(\"Cumulative\")[0]+\"Incremental\"\n",
    "    incremental_precip_columns.append(col_name)\n",
    "    dat[col_name]=dat[precip_col]-dat[precip_col].shift(1)\n",
    "    if not np.isnan(dat[precip_col][0]):\n",
    "        dat.ix[0, col_name]=0 #set first value to 0, not NAN IF the initial cumulative series was also not null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill Gaps -temp\n",
    " #### * 15 min data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Temperature - for primary sensor, fill gaps. \n",
    "#  for <3 len gap, fill with linear interpolation\n",
    "dat.loc[:,primary_temp_column]=dat[primary_temp_column].interpolate(method='linear', limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  for gaps >3, fill with average of passive temperature sensors, as long as the passive sensors agree\n",
    "\n",
    "#Store locations of long NAN gaps to be filled\n",
    "primary_temp_null_indx=dat[primary_temp_column].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#List alternate temp columns\n",
    "secondary_temp_columns=list(set(temp_columns)-set([primary_temp_column]))\n",
    "passive_temp_columns=[s for s in temp_columns if \"passive\" in s]\n",
    "\n",
    "#Subset data to alternate temperature columns\n",
    "secondary_temp_dat=dat[secondary_temp_columns].copy()\n",
    "#Calculate the mean of the secondary temp values\n",
    "secondary_temp_dat['temp_mean']=secondary_temp_dat[secondary_temp_columns].mean(axis=1)\n",
    "#Calculate standard dev. of secondary temp values\n",
    "secondary_temp_dat['temp_sd']=secondary_temp_dat[secondary_temp_columns].std(axis=1)\n",
    "#Calculate temperature difference between avg. of other temperatures\n",
    "secondary_temp_dat['temp_diff']=abs(dat[primary_temp_column]-secondary_temp_dat.mean(axis=1))\n",
    "#Calculate the median of secondary temp values\n",
    "secondary_temp_dat['temp_median']=secondary_temp_dat[secondary_temp_columns].median(axis=1)\n",
    "#Calculate mean of passive temperature sensors (if a sensor is missing, mean will be NAN)\n",
    "secondary_temp_dat['passive_average']=dat[passive_temp_columns].mean(axis=1, skipna=False)\n",
    "#Calculate difference of 2 passive sensors from one another\n",
    "secondary_temp_dat['passive_difference_between_sensors']=abs(dat[passive_temp_columns[0]]-dat[passive_temp_columns[1]])\n",
    "\n",
    "#Fill remaining gaps (>3 length) in primary timeseries with average of all other sensors\n",
    "dat.loc[dat[primary_temp_column].isnull(), primary_temp_column]=secondary_temp_dat.temp_mean[dat[primary_temp_column].isnull()]\n",
    "\n",
    "#Second round of interpolating small gaps\n",
    "dat[primary_temp_column]=dat[primary_temp_column].interpolate(method='linear', limit=3) #interpolate small gaps again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Find places where passive differs from aspirated\n",
    "asp_more_than_2deg_diff_from_passivemean_idx=(abs(dat[primary_temp_column]- secondary_temp_dat.passive_average))>2 #difference between asp and passive mean > 2 deg\n",
    "\n",
    "#In places where the passive AGREE with eachother, but DISAGREE with the aspirated mean, set main aspirated T to mean of passive.\n",
    "passive_sensors_agree_with_eachother_2deg_idx=secondary_temp_dat.passive_difference_between_sensors<2 #passive sensors agree with eachother (<2 deg diff)\n",
    "dat.loc[asp_more_than_2deg_diff_from_passivemean_idx & passive_sensors_agree_with_eachother_2deg_idx, primary_temp_column]=secondary_temp_dat.loc[asp_more_than_2deg_diff_from_passivemean_idx & passive_sensors_agree_with_eachother_2deg_idx,'passive_average'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Final outlier strip\n",
    "dat[primary_temp_column]=LVL1.hampel(dat[primary_temp_column], k=7) #this may not be neccessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save final 15 minute data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_columns=[primary_temp_column] +incremental_precip_columns+general_data_columns #columns to include in output\n",
    "save_name=Glacier.lower()+ Station + \"_15min_\"+\"LVL2.csv\" #filename\n",
    "save_pth=os.path.join(save_dir, save_name)\n",
    "\n",
    "save_dat=dat[out_columns] #dataframe with final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat[out_columns].to_csv(save_pth, float_format='%g', date_format=date_format) #save data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hourly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create Hourly Data -\n",
    "#Temperature\n",
    "hourly_dat=pd.DataFrame()\n",
    "for temp_col in temp_columns:\n",
    "    #Create WMO Mean Temp\n",
    "    hourly_dat[temp_col+\"_min\"]=dat[temp_col].resample('H').min()\n",
    "    hourly_dat[temp_col+ \"_max\"]=dat[temp_col].resample('H').max()\n",
    "    hourly_dat[temp_col+\"_WMO\"]=hourly_dat[[temp_col+\"_min\", temp_col+'_max']].mean(axis=1)\n",
    "    #Create USGS Mean Temp\n",
    "    hourly_dat[temp_col+\"_USGS\"]=dat[temp_col].resample('H').mean()\n",
    "    \n",
    "#Precipitation\n",
    "for incremental_precip_col in incremental_precip_columns:\n",
    "    hourly_dat[incremental_precip_col]=dat[incremental_precip_col].resample('H', label='left').sum() #all precip recieved during his hour\n",
    "    \n",
    "#Other Data Types (that can be aggregated with a simple mean)\n",
    "for general_data_col in general_data_columns:\n",
    "    hourly_dat[general_data_col]=dat[general_data_col].resample('H').mean()\n",
    "\n",
    "#Wind Direction - this process is for data that is logged as vector-averaged \n",
    "  # for data that is not, use LVL1.vector_average_wind_direction\n",
    "for wd_col in wind_dir_columns:\n",
    "#Convert to raidans\n",
    "    dat['wind_dir_cos']=np.cos(dat[wd_col]*(np.pi/180))\n",
    "    dat['wind_dir_sin']=np.sin(dat[wd_col]*(np.pi/180))\n",
    "\n",
    "    #Calculate mean of x and y directions in radian space\n",
    "    hourly_dat['wind_dir_cos']=dat.wind_dir_cos.resample('H').mean()\n",
    "    hourly_dat['wind_dir_sin']=dat.wind_dir_sin.resample('H').mean()\n",
    "\n",
    "    #Convert back to 0-360 coordinates\n",
    "    hourly_dat[wd_col]=(np.arctan2(hourly_dat.wind_dir_sin, hourly_dat.wind_dir_cos) * 180/np.pi)\n",
    "    hourly_dat.loc[hourly_dat[wd_col]<0, wd_col]+=360 #add 360 where hourly dat less than 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:/Project Data/GlacierData/Benchmark_Program/Data/Gulkana/AllYears/Wx/LVL2/emily/gulkana1725_hourly_LVL2.csv\n"
     ]
    }
   ],
   "source": [
    "out_temp_columns = [s for s in hourly_dat.columns if primary_temp_column in s]\n",
    "\n",
    "out_columns=out_temp_columns+incremental_precip_columns+general_data_columns+ wind_dir_columns #columns to include in output\n",
    "save_name=Glacier.lower()+ Station + \"_hourly_\"+\"LVL2.csv\" #filename\n",
    "save_pth=os.path.join(save_dir, save_name)\n",
    "\n",
    "hourly_dat[out_columns][:-1].to_csv(save_pth, float_format='%g') #write selected columns; omit last row (unlikely to be complete, with download)\n",
    "print(save_pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_dat=pd.DataFrame() #create empty dataframe\n",
    "\n",
    "#Temperature\n",
    "for temp_col in temp_columns:\n",
    "    #Create WMO Mean Temp\n",
    "    daily_dat[temp_col+\"_min\"]=dat[temp_col].resample('D').min()\n",
    "    daily_dat[temp_col+ \"_max\"]=dat[temp_col].resample('D').max()\n",
    "    daily_dat[temp_col+\"_WMO\"]=daily_dat[[temp_col+\"_min\", temp_col+'_max']].mean(axis=1)\n",
    "    #Create USGS Mean Temp\n",
    "    daily_dat[temp_col+\"_USGS\"]=dat[temp_col].resample('D').mean()    \n",
    "    \n",
    "#Precipitation\n",
    "for incremental_precip_col in incremental_precip_columns:\n",
    "    daily_dat[incremental_precip_col]=dat[incremental_precip_col].resample('D', label='left').sum() #all precip recieved during this day; label on right\n",
    "    \n",
    "#Other Data Types (that can be aggregated with a simple mean)\n",
    "for general_data_col in general_data_columns:\n",
    "    daily_dat[general_data_col]=dat[general_data_col].resample('D').mean()\n",
    "\n",
    "#Wind Direction - this process is for data that is logged as vector-averaged \n",
    "  # for data that is not, use LVL2.vector_average_wind_direction to create\n",
    "for wd_col in wind_dir_columns:    \n",
    "    #Convert to raidans\n",
    "    dat['wind_dir_cos']=np.cos(dat[wd_col]*(np.pi/180))\n",
    "    dat['wind_dir_sin']=np.sin(dat[wd_col]*(np.pi/180))\n",
    "\n",
    "    #Calculate mean of x and y directions in radian space\n",
    "    daily_dat['wind_dir_cos']=dat.wind_dir_cos.resample('D').mean()\n",
    "    daily_dat['wind_dir_sin']=dat.wind_dir_sin.resample('D').mean()\n",
    "\n",
    "    #Convert back to 0-360 coordinates\n",
    "    daily_dat[wd_col]=(np.arctan2(daily_dat.wind_dir_sin, daily_dat.wind_dir_cos) * 180/np.pi)\n",
    "    daily_dat.loc[daily_dat[wd_col]<0, wd_col]+=360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_temp_columns = [s for s in daily_dat.columns if primary_temp_column in s] #only save select temperature columns\n",
    "\n",
    "out_columns=out_temp_columns+incremental_precip_columns+general_data_columns+ wind_dir_columns #columns to include in output\n",
    "save_name=Glacier.lower()+ Station + \"_daily_\"+\"LVL2.csv\" #filename\n",
    "save_pth=os.path.join(save_dir, save_name) #location to save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Set number of decimals to save for each type of data. Split into 3 separate loops for easy option of changing for each type.\n",
    "for col in out_temp_columns:\n",
    "    daily_dat[col]=[\"%.1f\" %x for x in daily_dat[col]] #round temperature to 1 decimal places; store as string \n",
    "\n",
    "for col in incremental_precip_columns:\n",
    "    daily_dat[col]=[\"%.1f\" %x for x in daily_dat[col]] #round precip to 1 decimal place\n",
    "\n",
    "for col in general_data_columns:\n",
    "    daily_dat[col]=[\"%.1f\" %x for x in daily_dat[col]] #round general data cols to 1 decimal place\n",
    "\n",
    "for col in wind_dir_columns:\n",
    "    daily_dat[col]=[\"%.0f\" %x for x in daily_dat[col]] #wind direction; no decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rename columns to standard\n",
    "# #Generic Temperature Label\n",
    "# final_names=[x.replace(primary_temp_column, 'Temp') for x in out_columns]\n",
    "# #Change precip label from Incremental to Precip (preserve type label)\n",
    "# final_names=[x.replace(\"Incremental\", \"_Precip\") for x in final_names]\n",
    "# save_dat.columns=final_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_dat=daily_dat[out_columns][:-1] #remove last row; day is not complete upon download\n",
    "save_dat.to_csv(save_pth, float_format='%g', date_format='%Y/%m/%d') #write selected columns; omit last row (unlikely to be complete, with download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q:/Project Data/GlacierData/Benchmark_Program/Data/Gulkana/AllYears/Wx/LVL2/emily/gulkana1725_daily_LVL2.csv'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TAspirated1_min</th>\n",
       "      <th>TAspirated1_max</th>\n",
       "      <th>TAspirated1_WMO</th>\n",
       "      <th>TAspirated1_USGS</th>\n",
       "      <th>StageIncremental</th>\n",
       "      <th>TPGIncremental</th>\n",
       "      <th>RelHum</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>RadiationIn</th>\n",
       "      <th>RadiationOut</th>\n",
       "      <th>SnowDepth</th>\n",
       "      <th>WindDir</th>\n",
       "      <th>VecAvgWindDir</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-18</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.6</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.2</td>\n",
       "      <td>nan</td>\n",
       "      <td>107.3</td>\n",
       "      <td>19.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>nan</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-19</th>\n",
       "      <td>-1.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>nan</td>\n",
       "      <td>8.1</td>\n",
       "      <td>nan</td>\n",
       "      <td>2.4</td>\n",
       "      <td>nan</td>\n",
       "      <td>151.3</td>\n",
       "      <td>50.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>nan</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-20</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>nan</td>\n",
       "      <td>11.6</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.1</td>\n",
       "      <td>nan</td>\n",
       "      <td>98.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-21</th>\n",
       "      <td>1.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>148.4</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>nan</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-22</th>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>nan</td>\n",
       "      <td>3.3</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.8</td>\n",
       "      <td>nan</td>\n",
       "      <td>128.7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>nan</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TAspirated1_min TAspirated1_max TAspirated1_WMO TAspirated1_USGS  \\\n",
       "local_time                                                                    \n",
       "2017-08-18            -1.0             0.1            -0.5             -0.5   \n",
       "2017-08-19            -1.8             2.9             0.5             -0.1   \n",
       "2017-08-20            -0.1             3.0             1.4              0.8   \n",
       "2017-08-21             1.3             6.0             3.6              4.4   \n",
       "2017-08-22             3.8             6.7             5.2              5.2   \n",
       "\n",
       "           StageIncremental TPGIncremental RelHum WindSpeed WindGustSpeed  \\\n",
       "local_time                                                                  \n",
       "2017-08-18              nan            4.6    nan       1.2           nan   \n",
       "2017-08-19              nan            8.1    nan       2.4           nan   \n",
       "2017-08-20              nan           11.6    nan       4.1           nan   \n",
       "2017-08-21              nan            0.2    nan       4.0           nan   \n",
       "2017-08-22              nan            3.3    nan       1.8           nan   \n",
       "\n",
       "           RadiationIn RadiationOut SnowDepth WindDir VecAvgWindDir  \n",
       "local_time                                                           \n",
       "2017-08-18       107.3         19.8       2.3     nan           198  \n",
       "2017-08-19       151.3         50.7       2.2     nan           205  \n",
       "2017-08-20        98.3         24.3       2.0     nan           207  \n",
       "2017-08-21       148.4         26.0       2.2     nan            14  \n",
       "2017-08-22       128.7         20.0       2.3     nan            11  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dat.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
