{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L0 data clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import imp\n",
    "import datetime\n",
    "import pytz\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import self-written libraries\n",
    "import LVL1\n",
    "import settings\n",
    "from settings import Glacier, Station, base_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Glacier and Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Glacier='Wolverine'\n",
    "Station='990'\n",
    "\n",
    "data_columns, general_data_columns, out_date_format, precip_columns, precip_gage_change, primary_temp_column, temp_columns, timezone, wind_col, wind_dir_columns = settings.get_settings(settings.Glacier, settings.Station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Are there newly downloaded data?\n",
    "new_data=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if new_data:\n",
    "    add_new_logger_data_script_pth='\"' + base_path + 'Code/Weather/LVL_0/ConcatenateRawWxData.py'+ '\"'\n",
    "    %run $add_new_logger_data_script_pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (Glacier + Station =='Wolverine370')| (Glacier =='SouthCascade'):\n",
    "    print ('STOP: not needed here; start at L1. All data from NWIS')\n",
    "    print('Ensure that Add1990sDataFromNWIS.py has been run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (Glacier + Station== 'Wolverine1420') | (Glacier + Station== 'Gulkana1920'): #If a JWS station, which logs @ 5 minutes\n",
    "    if new_data:\n",
    "        convert5minto15min_script_pth='\"' + base_path + 'Code/Weather/LVL_0/ConvertFrom5minTo15minData_JWS.py'+ '\"'\n",
    "\n",
    "        %run $convert5minto15min_script_pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#At the Wolverine high JWS site, add TPG (was logged internally, never wired in to logger direclty before moving).\n",
    "if (Glacier + Station== 'Wolverine1420'): #add TPG log to the high wolverine station, during the time which it existed there.\n",
    "    addTPGdata_script_pth='\"' + base_path + 'Code/Weather/LVL_0/AddWolverineTPGData.py'+ '\"'\n",
    "    \n",
    "    %run $addTPGdata_script_pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in data\n",
    "folder=base_path+ r\"Data/\" + Glacier+ \"/AllYears/Wx/Raw\" #folder cont\n",
    "file_label='_15min_all' #used for importting and output name\n",
    "file=Glacier.lower()+Station+file_label+\".csv\" #filename; change if yours different\n",
    "pth=os.path.join(folder, file) #path to data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set constants for input data\n",
    "date_format='%m/%d/%Y %H:%M:%S' #input date format (change if yours is different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read file: Q:/Project Data/GlacierData/Benchmark_Program/Data/Wolverine/AllYears/Wx/Raw\\wolverine990_15min_all.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ehbaker\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Instrument</th>\n",
       "      <th>Value</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Flag</th>\n",
       "      <th>DateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/01/2010</td>\n",
       "      <td>23:15:00</td>\n",
       "      <td>WindDir</td>\n",
       "      <td>900.0</td>\n",
       "      <td>Deg</td>\n",
       "      <td>G</td>\n",
       "      <td>03/01/2010 23:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03/01/2010</td>\n",
       "      <td>23:15:00</td>\n",
       "      <td>PrecipStage</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>03/01/2010 23:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/01/2010</td>\n",
       "      <td>23:15:00</td>\n",
       "      <td>WindSpeed</td>\n",
       "      <td>0.9</td>\n",
       "      <td>m/s</td>\n",
       "      <td>G</td>\n",
       "      <td>03/01/2010 23:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03/01/2010</td>\n",
       "      <td>23:28:00</td>\n",
       "      <td>WindSpeed</td>\n",
       "      <td>0.4</td>\n",
       "      <td>m/s</td>\n",
       "      <td>G</td>\n",
       "      <td>03/01/2010 23:28:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03/01/2010</td>\n",
       "      <td>23:28:00</td>\n",
       "      <td>WindDir</td>\n",
       "      <td>914.0</td>\n",
       "      <td>Deg</td>\n",
       "      <td>G</td>\n",
       "      <td>03/01/2010 23:28:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time   Instrument  Value Unit Flag             DateTime\n",
       "0  03/01/2010  23:15:00      WindDir  900.0  Deg    G  03/01/2010 23:15:00\n",
       "1  03/01/2010  23:15:00  PrecipStage    0.0    M    B  03/01/2010 23:15:00\n",
       "2  03/01/2010  23:15:00    WindSpeed    0.9  m/s    G  03/01/2010 23:15:00\n",
       "3  03/01/2010  23:28:00    WindSpeed    0.4  m/s    G  03/01/2010 23:28:00\n",
       "4  03/01/2010  23:28:00      WindDir  914.0  Deg    G  03/01/2010 23:28:00"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat=pd.read_csv(pth)\n",
    "print(\"read file: \" + pth)\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Logger time to UTC and Local Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Logger records on UTC -8; convert to local time\n",
    "#Create date-time column\n",
    "#dat['DateTime']=dat.Date+ \" \" + dat.Time #this is needed for non-cumulative processing\n",
    "dat.loc[:,'DateTime']=pd.to_datetime(dat['DateTime'], format=date_format) #set to date-time from string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>UTC_time</th>\n",
       "      <th>Tpassive1</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>WindDir</th>\n",
       "      <th>RelHum</th>\n",
       "      <th>SWup_incoming</th>\n",
       "      <th>SWdn_outgoing</th>\n",
       "      <th>LWup_incoming</th>\n",
       "      <th>LWdn_outgoing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-06-28 14:00:00</td>\n",
       "      <td>2006/06/28 20:00</td>\n",
       "      <td>13.480</td>\n",
       "      <td>4.05400</td>\n",
       "      <td>245.90</td>\n",
       "      <td>51.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-06-28 14:15:00</td>\n",
       "      <td>2006/06/28 20:15</td>\n",
       "      <td>13.625</td>\n",
       "      <td>4.35025</td>\n",
       "      <td>248.42</td>\n",
       "      <td>49.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-06-28 14:30:00</td>\n",
       "      <td>2006/06/28 20:30</td>\n",
       "      <td>13.770</td>\n",
       "      <td>4.64650</td>\n",
       "      <td>250.95</td>\n",
       "      <td>47.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-06-28 14:45:00</td>\n",
       "      <td>2006/06/28 20:45</td>\n",
       "      <td>13.915</td>\n",
       "      <td>4.94275</td>\n",
       "      <td>253.48</td>\n",
       "      <td>45.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-06-28 15:00:00</td>\n",
       "      <td>2006/06/28 21:00</td>\n",
       "      <td>14.060</td>\n",
       "      <td>5.23900</td>\n",
       "      <td>256.00</td>\n",
       "      <td>43.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DateTime          UTC_time  Tpassive1  WindSpeed  WindDir  \\\n",
       "0 2006-06-28 14:00:00  2006/06/28 20:00     13.480    4.05400   245.90   \n",
       "1 2006-06-28 14:15:00  2006/06/28 20:15     13.625    4.35025   248.42   \n",
       "2 2006-06-28 14:30:00  2006/06/28 20:30     13.770    4.64650   250.95   \n",
       "3 2006-06-28 14:45:00  2006/06/28 20:45     13.915    4.94275   253.48   \n",
       "4 2006-06-28 15:00:00  2006/06/28 21:00     14.060    5.23900   256.00   \n",
       "\n",
       "   RelHum  SWup_incoming  SWdn_outgoing  LWup_incoming  LWdn_outgoing  \n",
       "0   51.93            NaN            NaN            NaN            NaN  \n",
       "1   49.90            NaN            NaN            NaN            NaN  \n",
       "2   47.87            NaN            NaN            NaN            NaN  \n",
       "3   45.84            NaN            NaN            NaN            NaN  \n",
       "4   43.81            NaN            NaN            NaN            NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Correct for time slips\n",
    "dat['DateTime']=dat['DateTime'].dt.round('15min') #round time to the nearest 15 minute value\n",
    "\n",
    "#Convert to UTC time, if logger is logging in UTC-8 (true at some stations)\n",
    "if (Glacier+Station=='Wolverine990') | (Glacier+Station=='Gulkana1480') | (Glacier+Station=='Gulkana1920') | (Glacier+Station=='Wolverine1420'):\n",
    "    dat['UTC_col']=dat.DateTime + datetime.timedelta(hours=8)\n",
    "if (Glacier+Station=='Gulkana1725'):\n",
    "    dat['UTC_col']=dat.DateTime #logger is already in UTC time\n",
    "if Glacier + Station=='Sperry2440':\n",
    "    dat['UTC_col']=dat.UTC_time.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat['UTC_col']=pd.to_datetime(dat['UTC_col'], format=date_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Set timezone of known UTC column\n",
    "dat['UTC_col'].timezone='UTC'\n",
    "#Create column for local time\n",
    "local_timezone=pytz.timezone(timezone) #create local timezone object (e.g. AK time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat=dat.set_index('UTC_col')\n",
    "#Create column for local time\n",
    "local_timezone=pytz.timezone(timezone) #create local timezone object (e.g. AK time)\n",
    "\n",
    "#Create local time\n",
    "dat['local_time'] = dat.index.tz_localize('UTC').tz_convert(local_timezone)\n",
    "\n",
    "dat['index_local_time']=dat.local_time.copy()\n",
    "\n",
    "#Set index to local time\n",
    "dat=dat.set_index('index_local_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Instrument'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\ehbaker\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2133\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2134\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2135\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\src\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\src\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Instrument'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-760bbe1c0405>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m#Drop duplicates that have same instrument name and date/time stamp (from multiple downloads of same portion of data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DateTime'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Instrument'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'first'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#gets rid of overlaps (i.e. multiple downloads of same bit of data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\ehbaker\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\util\\decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ehbaker\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop_duplicates\u001b[0;34m(self, subset, keep, inplace)\u001b[0m\n\u001b[1;32m   3136\u001b[0m         \u001b[0mdeduplicated\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3137\u001b[0m         \"\"\"\n\u001b[0;32m-> 3138\u001b[0;31m         \u001b[0mduplicated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ehbaker\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\util\\decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ehbaker\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mduplicated\u001b[0;34m(self, subset, keep)\u001b[0m\n\u001b[1;32m   3186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3187\u001b[0m         \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3188\u001b[0;31m         \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3190\u001b[0m         \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_group_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxnull\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ehbaker\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3185\u001b[0m             \u001b[0msubset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3187\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3188\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ehbaker\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2057\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ehbaker\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2067\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ehbaker\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ehbaker\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3542\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3543\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3544\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3545\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ehbaker\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2134\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2136\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\src\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\src\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Instrument'"
     ]
    }
   ],
   "source": [
    "#Drop duplicates that have same instrument name and date/time stamp (from multiple downloads of same portion of data)\n",
    "dat=dat.drop_duplicates(subset=['DateTime', 'Instrument'], keep='first') #gets rid of overlaps (i.e. multiple downloads of same bit of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat.Value[dat.Instrument=='AirTemp'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Instrument Label Change - if same label has been used for different quantities thru time: separate into 2 distinct labels.\n",
    "if Glacier + Station==\"Wolverine990\":\n",
    "    dat.loc[(dat.Instrument=='WD') & (dat.index<'2015-09-06 17:15'), 'Instrument']='WindDir' #before this date, \"WD\" was simply wind direction; after, is vector-averaged\n",
    "    dat.loc[(dat.Instrument=='WD') & (dat.index>='2015-09-06 17:15'), 'Instrument']='WDSA' \n",
    "    \n",
    "if Glacier + Station==\"Gulkana1480\":\n",
    "    dat.loc[(dat.Instrument=='WD') & (dat.index<'2015-09-28 12:00'), 'Instrument']='WindDir' #before this date, \"WD\" was simply wind direction; after, is vector-averaged\n",
    "    dat.loc[(dat.Instrument=='WD') & (dat.index>='2015-09-28 12:00'), 'Instrument']='WDSA' \n",
    "    \n",
    "#Gulkana 1725 has had consistent variable naming throughout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidate Sensor Naming\n",
    "#### Has varied thru time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If site does NOT have a given sensor, leave label, create empty list\n",
    "\n",
    "if Glacier + Station =='Wolverine990':  \n",
    "    #Name recorded on the logger changed thru time; indicate which are grouped (i.e. logging same variable) here\n",
    "    wind_gust_labels=['WindGusts', 'WG', 'WSG']\n",
    "    wind_speed_labels=['AvgWind', 'WS'] #this is NOT vector-averaged wind speed\n",
    "    vec_avg_wind_dir=['WDSA']\n",
    "    wind_dir_labels=['WindDir']\n",
    "    temp_unasp1_labels=['AirTemp1', 'T1', 'T']\n",
    "    temp_unasp2_labels=['AirTemp2', 'T2']\n",
    "    temp_asp1_labels=['AirTempAsp', 'AspT', 'AT']\n",
    "    temp_asp2_labels=['ASPTRH', 'AT2']\n",
    "    precip_stage_labels=['PR']\n",
    "    precip_weighing_labels=['TPG', 'PC']\n",
    "    precip_incremental_labels=[]\n",
    "    rel_hum_labels=['RH']\n",
    "    barometer_labels=['B', 'BAROMETER']\n",
    "    logger_bat_label=['BV']\n",
    "    logger_temp_label=['Tinternal']\n",
    "    bad_labels=['PrecipStage', 'AirTemp3', 'Air Temp w/FanN', 'AirTemp w/Fan', 'VectorAvgWindDir', 'PS', 'MWD', 'WDA'] #labels containing only bad data; introduced during maintenence etc.\n",
    "    radiation_up_labels=[]\n",
    "    radiation_down_labels=[]\n",
    "    snow_depth_labels=[] \n",
    "    \n",
    "if Glacier + Station =='Gulkana1480':  \n",
    "    #Name recorded on the logger changed thru time; indicate which are grouped (i.e. logging same variable) here\n",
    "    wind_gust_labels=['WSG']\n",
    "    wind_speed_labels=['WindSpeed', 'WS']\n",
    "    vec_avg_wind_dir=['WDSA']\n",
    "    wind_dir_labels=['WindDir'] #this is NOT-vector average wind direction\n",
    "    temp_unasp1_labels=['AirTemp1', 'T1', 'T']\n",
    "    temp_unasp2_labels=['AirTemp2', 'T2']\n",
    "    temp_asp1_labels=['AspT', 'AT']\n",
    "    temp_asp2_labels=['AT2']\n",
    "    precip_stage_labels=['PR'] #precip doesn't begin until 2010-07; before this, is recording, but logger only has 0 precip\n",
    "    precip_weighing_labels=['TPG', 'PC']\n",
    "    precip_incremental_labels=[]\n",
    "    rel_hum_labels=['RH']\n",
    "    barometer_labels=[] #no barometer at this station\n",
    "    logger_bat_label=['BV']\n",
    "    logger_temp_label=['Tinternal']\n",
    "    bad_labels=['PrecipStage', 'AirTemp3', 'Stage'] #labels containing only bad data; introduced during maintenence etc.\n",
    "    radiation_up_labels=[]\n",
    "    radiation_down_labels=[]\n",
    "    snow_depth_labels=[]    \n",
    "    \n",
    "if Glacier + Station=='Gulkana1725':\n",
    "    #Only a single name thru time; no changes @ 1725\n",
    "    wind_gust_labels=[]#no wind gust recorded\n",
    "    wind_speed_labels=['MS']\n",
    "    vec_avg_wind_dir=['MD']\n",
    "    wind_dir_labels=[] #this is NOT-vector average wind direction\n",
    "    temp_unasp1_labels=['TA'] #TA is NOT Aspriated; it's Temperature, Air\n",
    "    temp_unasp2_labels=['T']\n",
    "    temp_asp1_labels=[]\n",
    "    temp_asp2_labels=[]\n",
    "    precip_stage_labels=[]\n",
    "    precip_weighing_labels=['PC']\n",
    "    precip_incremental_labels=[]\n",
    "    rel_hum_labels=[]\n",
    "    barometer_labels=[] #no barometer at this station\n",
    "    logger_bat_label=['VB']\n",
    "    logger_temp_label=[]\n",
    "    bad_labels=[]\n",
    "    radiation_up_labels=['RU']\n",
    "    radiation_down_labels=['RD']\n",
    "    snow_depth_labels=['DS']\n",
    "    \n",
    "if (Glacier + Station=='Gulkana1920') | (Glacier + Station=='Wolverine1420'): #same program and same variable naming at JWS stations\n",
    "    wind_gust_labels=[]#no wind gust recorded\n",
    "    wind_speed_labels=['WS_ms_S_WVT']\n",
    "    vec_avg_wind_dir=['WindDir_D1_WVT'] #I am guessing this is vec acerage; should come back and check program before using\n",
    "    wind_dir_labels=[] #this is NOT-vector average wind direction\n",
    "    temp_unasp1_labels=['AirTempC_Avg']\n",
    "    temp_unasp2_labels=[]\n",
    "    temp_asp1_labels=[]\n",
    "    temp_asp2_labels=[]\n",
    "    precip_stage_labels=[]\n",
    "    precip_weighing_labels=[]\n",
    "    precip_incremental_labels=[]\n",
    "    if Station=='Wolverine1420':#only true at Wolverine\n",
    "        precip_weighing_labels=['TPGCumulative']\n",
    "    rel_hum_labels=['RH']\n",
    "    barometer_labels=['BP_inHg_Avg']\n",
    "    logger_bat_label=['BattV_Avg']\n",
    "    logger_temp_label=[]\n",
    "    bad_labels=[]\n",
    "    radiation_up_labels=['PyrnUp_Avg']\n",
    "    radiation_down_labels=['PyrnDn_Avg']\n",
    "    snow_depth_labels=[]\n",
    "\n",
    "    \n",
    "    #COME BACK AND START HERE AFTER FIELDWORK WITH AVO!!\n",
    "if Glacier =='JuneauIcefield' and \"AWS\" in Station: #differentiate between 3 AWS stations, vs. jirp hobo loggers\n",
    "    wind_gust_labels=['WindSpMax', 'WindSpGust', 'WindSP_Gust']#no wind gust recorded\n",
    "    wind_speed_labels=['WS_ms_S_WVT', 'WindSpeed', 'WindSp', 'WindSP']\n",
    "    vec_avg_wind_dir=['WindDir_D1_WVT', 'WindDir_VecAvg'] #I am guessing this is vec acerage; should come back and check program before using\n",
    "    wind_dir_labels=['WindDir'] #this is NOT-vector average wind direction\n",
    "    temp_unasp1_labels=['AirTC_Avg', 'AirTemp']\n",
    "    temp_unasp2_labels=[]\n",
    "    temp_asp1_labels=[]\n",
    "    temp_asp2_labels=[]\n",
    "    precip_stage_labels=[]\n",
    "    precip_weighing_labels=[]\n",
    "    precip_incremental_labels=['Precip_m']\n",
    "    rel_hum_labels=['RH']\n",
    "    barometer_labels=['BP_mbar', 'BP_kPa_Avg', 'Baro_Kpa', 'Baro']\n",
    "    logger_bat_label=['BattV_Avg']\n",
    "    logger_temp_label=[]\n",
    "    bad_labels=['Time']\n",
    "    radiation_up_labels=['PyrnUp_Avg', 'SolRad']\n",
    "    radiation_down_labels=['PyrnDn_Avg']\n",
    "    snow_depth_labels=['TCDT', 'SnowDep1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat.Instrument.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Rename instruments \n",
    "dat.loc[dat.Instrument.isin(wind_gust_labels), \"Instrument\"]='WindGustSpeed'\n",
    "dat.loc[dat.Instrument.isin(wind_speed_labels), \"Instrument\"]='WindSpeed'\n",
    "dat.loc[dat.Instrument.isin(wind_dir_labels), \"Instrument\"]='WindDir'\n",
    "dat.loc[dat.Instrument.isin(vec_avg_wind_dir), \"Instrument\"]='VecAvgWindDir'\n",
    "dat.loc[dat.Instrument.isin(temp_unasp1_labels), \"Instrument\"]='Tpassive1'\n",
    "dat.loc[dat.Instrument.isin(temp_unasp2_labels), \"Instrument\"]='Tpassive2'\n",
    "dat.loc[dat.Instrument.isin(temp_asp1_labels), \"Instrument\"]='TAspirated1'\n",
    "dat.loc[dat.Instrument.isin(temp_asp2_labels), \"Instrument\"]='TAspirated2'\n",
    "dat.loc[dat.Instrument.isin(precip_stage_labels), \"Instrument\"]='StageCumulative'\n",
    "dat.loc[dat.Instrument.isin(precip_weighing_labels), \"Instrument\"]='TPGCumulative'\n",
    "dat.loc[dat.Instrument.isin(precip_incremental_labels), \"Instrument\"]='IncrementalPrecip'\n",
    "dat.loc[dat.Instrument.isin(rel_hum_labels), \"Instrument\"]='RelHum'\n",
    "dat.loc[dat.Instrument.isin(barometer_labels), \"Instrument\"]='Barom'\n",
    "dat.loc[dat.Instrument.isin(logger_bat_label), \"Instrument\"]='LoggerBattery'\n",
    "dat.loc[dat.Instrument.isin(logger_temp_label), \"Instrument\"]='LoggerTemp'\n",
    "dat.loc[dat.Instrument.isin(radiation_up_labels), \"Instrument\"]='RadiationIn'\n",
    "dat.loc[dat.Instrument.isin(radiation_down_labels), \"Instrument\"]='RadiationOut'\n",
    "dat.loc[dat.Instrument.isin(snow_depth_labels), \"Instrument\"]='SnowDepth'\n",
    "\n",
    "#Remove rows with bad data\n",
    "dat=dat[~dat.Instrument.isin(bad_labels)] #Remove where labels are bad; introduced during maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(dat.Instrument.unique())\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Cast the data from long -> wide format\n",
    "#dat=dat.reset_index() #reset index so all unique\n",
    "wide_dat=dat.pivot_table(columns='Instrument', values='Value', index='local_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wide_dat.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "wide_dat.Tpassive1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#List columns desired in output\n",
    "# out_columns=['UTC_time', 'local_time', 'Tpassive1', 'Tpassive2',\n",
    "#        'TAspirated1', 'TAspirated2', 'RelHum', 'StageCumulative',\n",
    "#        'TPGCumulative', 'WindSpeed', 'WindGustSpeed', 'WindDir', 'Barom',\n",
    "#         'VecAvgWindDir', 'RadiationIn', 'RadiationOut', 'SnowDepth', 'LoggerTemp', 'LoggerBattery']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This should NO LONGER be neccessary (~4/18/18); future processing can eliminate the all NAN columns\n",
    "#If this columns is not in dataframe, create\n",
    "# for col in out_columns:\n",
    "#     if col not in wide_dat.columns:\n",
    "#         wide_dat[col]=np.nan #create the column; fill with NANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reindex to 15min to ensure no timesteps are skipped\n",
    "wide_dat.sort_index(inplace=True)\n",
    "full_range_15_min = pd.date_range(wide_dat.index[0], wide_dat.index[-1], freq='15min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wide_dat.index[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_range_15_min[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wide_dat=wide_dat.reindex(index=full_range_15_min, fill_value=pd.np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Set output format of time\n",
    "wide_dat['UTC_time']=wide_dat.index.tz_convert('UTC').strftime(out_date_format)#Create column for true local time (as string, not UTC - X hrs)\n",
    "wide_dat['local_time']=wide_dat.index.tz_convert(timezone).strftime(out_date_format)#Create column for true local time (as string, not UTC - X hrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wide_dat=wide_dat.reset_index(drop=True).copy() #drop index in output dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_dat=wide_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#directory to save output data\n",
    "save_pth=base_path+ r\"Data/\" +Glacier+ r\"/AllYears/Wx/LVL0/\"\n",
    "out_nm=Glacier.lower()+ Station + file_label+ \"_LVL0.csv\"\n",
    "out_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_dat.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Set a nice column order to save\n",
    "#out_cols=['local_time', 'UTC_time']+temp_columns + precip_columns +[wind_col] +wind_dir_columns + list(set(save_dat.columns) - set(['local_time', 'UTC_time'] + temp_columns + precip_columns +[wind_col] +wind_dir_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_dat[['local_time', 'UTC_time'] +data_columns].to_csv(os.path.join(save_pth, out_nm), index=False, float_format='%g')\n",
    "print( \"saved to: \", save_pth+out_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#If this is the Nunatak station, fill gaps with Irridium telemetry\n",
    "if Glacier + Station=='Gulkana1725':\n",
    "    %run \"./Gulkana1725_FillGapsWithIrridium.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#If Wolv 990 or Gulkana 1480, add 1990s data from NWIS to extend record back in time\n",
    "if (Glacier + Station=='Wolverine990') | (Glacier + Station=='Gulkana1480'):    \n",
    "    %run \"./Add1990sDataFromNWIS.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('hey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_dat[['local_time', 'UTC_time'] +data_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
